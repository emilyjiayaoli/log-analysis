{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4181d83-8eef-4a5e-9b2b-9e459ced8e84",
   "metadata": {
    "id": "c4181d83-8eef-4a5e-9b2b-9e459ced8e84"
   },
   "source": [
    "# Building a Live RAG Pipeline over Google Drive Files\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/ingestion/ingestion_gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this guide we show you how to build a \"live\" RAG pipeline over Google Drive files.\n",
    "\n",
    "This pipeline will index Google Drive files and dump them to a Redis vector store. Afterwards, every time you rerun the ingestion pipeline, the pipeline will propagate **incremental updates**, so that only changed documents are updated in the vector store. This means that we don't re-index all the documents!\n",
    "\n",
    "We use the following [data source](https://drive.google.com/drive/folders/1RFhr3-KmOZCR5rtp4dlOMNl3LKe1kOA5?usp=sharing) - you will need to copy these files and upload them to your own Google Drive directory!\n",
    "\n",
    "**NOTE**: You will also need to setup a service account and credentials.json. See our LlamaHub page for the Google Drive loader for more details: https://llamahub.ai/l/readers/llama-index-readers-google?from=readers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7caa90-8418-4b1b-8dc4-31ac81da39f3",
   "metadata": {
    "id": "4a7caa90-8418-4b1b-8dc4-31ac81da39f3"
   },
   "source": [
    "## Setup\n",
    "\n",
    "We install required packages and launch the Redis Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d9bdd-1684-421f-ab6d-69112b652f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5179ede",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5179ede",
    "outputId": "4c560245-7a75-40f9-c30e-c6b8d20373ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-storage-docstore-redis\n",
    "%pip install llama-index-vector-stores-redis\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-readers-google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f480f0-71e4-4d50-8efa-deae20172764",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03f480f0-71e4-4d50-8efa-deae20172764",
    "outputId": "93d67e80-afea-4126-a194-c9168d7deb5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/redis-stack\" is already in use by container \"0f8431747c7706d69300b99a86c59aa98e9a7d7aeae2be59787afa9e42c90814\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "# if creating a new container\n",
    "!docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
    "# # if starting an existing container\n",
    "# !docker start -a redis-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b63d3831-70e9-4b7b-b876-1143fd580c6c",
   "metadata": {
    "id": "b63d3831-70e9-4b7b-b876-1143fd580c6c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-cf2vGKeLXFbUw702UEB0T3BlbkFJRJAY4TNZCAuErTbkbSsl' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0320e-47d6-48a8-9ba1-d844bb887cb5",
   "metadata": {
    "id": "69b0320e-47d6-48a8-9ba1-d844bb887cb5"
   },
   "source": [
    "## Define Ingestion Pipeline\n",
    "\n",
    "Here we define the ingestion pipeline. Given a set of documents, we will run sentence splitting/embedding transformations, and then load them into a Redis docstore/vector store.\n",
    "\n",
    "The vector store is for indexing the data + storing the embeddings, the docstore is for tracking duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f2871ad-1c14-49e4-b5ec-3e3eb96429f8",
   "metadata": {
    "id": "1f2871ad-1c14-49e4-b5ec-3e3eb96429f8"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.ingestion import (\n",
    "    DocstoreStrategy,\n",
    "    IngestionPipeline,\n",
    "    IngestionCache,\n",
    ")\n",
    "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.redis import RedisVectorStore\n",
    "\n",
    "from redisvl.schema import IndexSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baf744be",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "ac74203675564f14b73882a6ae270d18",
      "c93811def32744ce870253a77767777e",
      "8c237673c9ec4e22a4eba34c934cc322",
      "f66602de35274bb299d100783e73a01b",
      "7cc44d9f4fd84913b403a05124e71d9a",
      "f3a4992e06c44f2aac3f1a4d21e49065"
     ]
    },
    "id": "baf744be",
    "outputId": "12c2ba18-5efc-4353-cce5-48fd3935b722"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ca63bf0d-9455-40cb-b30f-9a23e1990c08",
   "metadata": {
    "id": "ca63bf0d-9455-40cb-b30f-9a23e1990c08"
   },
   "outputs": [],
   "source": [
    "# e: Define redis schema\n",
    "custom_schema = IndexSchema.from_dict(\n",
    "    {\n",
    "        \"index\": {\"name\": \"gdrive\", \"prefix\": \"doc\"},\n",
    "        # customize fields that are indexed\n",
    "        \"fields\": [\n",
    "            # required fields for llamaindex\n",
    "            {\"type\": \"tag\", \"name\": \"id\"},\n",
    "            {\"type\": \"tag\", \"name\": \"doc_id\"},\n",
    "            {\"type\": \"text\", \"name\": \"text\"},\n",
    "            # custom vector field for bge-small-en-v1.5 embeddings\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"name\": \"vector\",\n",
    "                \"attrs\": {\n",
    "                    \"dims\": 384,\n",
    "                    \"algorithm\": \"hnsw\",\n",
    "                    \"distance_metric\": \"cosine\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# e: define vector store given schema\n",
    "vector_store = RedisVectorStore(\n",
    "    schema=custom_schema,\n",
    "    redis_url=\"redis://localhost:6379\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "78043d63-bd88-4367-b883-5ad6075339ca",
   "metadata": {
    "id": "78043d63-bd88-4367-b883-5ad6075339ca"
   },
   "outputs": [],
   "source": [
    "# Optional: clear vector store if exists\n",
    "if vector_store.index_exists():\n",
    "    vector_store.delete_index()\n",
    "vector_store.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6d98845",
   "metadata": {
    "id": "e6d98845"
   },
   "outputs": [],
   "source": [
    "# Set up the ingestion cache layer\n",
    "cache = IngestionCache(\n",
    "    cache=RedisCache.from_host_and_port(\"localhost\", 6379),\n",
    "    collection=\"redis_cache\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d45c58a1-6c86-445c-9275-be28bd1c25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = RedisDocumentStore.from_host_and_port(\n",
    "        \"localhost\", 6379, namespace=\"document_store\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3be817bd-81a1-436f-8f92-3eb48531c915",
   "metadata": {
    "id": "3be817bd-81a1-436f-8f92-3eb48531c915"
   },
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        embed_model,\n",
    "    ],\n",
    "    docstore=docstore,\n",
    "    vector_store=vector_store,\n",
    "    cache=cache,\n",
    "    docstore_strategy=DocstoreStrategy.UPSERTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a873168-f735-43cd-b511-0bb569f9c8b4",
   "metadata": {
    "id": "6a873168-f735-43cd-b511-0bb569f9c8b4"
   },
   "source": [
    "### Define our Vector Store Index\n",
    "\n",
    "We define our index to wrap the underlying vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5affc83-b5f0-40c9-a8a1-b4ddd67fa62b",
   "metadata": {
    "id": "d5affc83-b5f0-40c9-a8a1-b4ddd67fa62b"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    pipeline.vector_store, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f9de5-4373-458b-b6cf-a8173f3e9a52",
   "metadata": {
    "id": "343f9de5-4373-458b-b6cf-a8173f3e9a52"
   },
   "source": [
    "## Load Initial Data\n",
    "\n",
    "Here we load data from our [Google Drive Loader](https://llamahub.ai/l/readers/llama-index-readers-google?from=readers) on LlamaHub.\n",
    "\n",
    "The loaded docs are the header sections of our [Use Cases from our documentation](https://docs.llamaindex.ai/en/latest/use_cases/q_and_a/root.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2c1c0d28-f18a-4efc-b6bf-9173016df8ba",
   "metadata": {
    "id": "2c1c0d28-f18a-4efc-b6bf-9173016df8ba"
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.google import GoogleDriveReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "983b9e84-b546-4b5a-9072-c6b3c8ec8699",
   "metadata": {
    "id": "983b9e84-b546-4b5a-9072-c6b3c8ec8699"
   },
   "outputs": [],
   "source": [
    "loader = GoogleDriveReader(service_account_key={\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"llamaindex-425923\",\n",
    "  \"private_key_id\": \"842e330bbcfd7c7525fce7f7d14ab161f056d717\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCqEkUMqdkWMrn6\\nCkePQnTih2EOE/aD66crON+vFLZhC8nwTsbMoHWgu6QegRkn+9mm8/yp1wDuV8jF\\nGztVF4pPA9pHLtoUliAR4qlO71mejElDcr5+9TUEu0BZV5maihQyMOi/ZAgOyx6N\\nwUp1EqUTpt8EY+NyjAVU4EGolPJil0D0ltiu3wUKEYhCRPUifS2aO5iKEk5ipkaq\\nkn87ar3Tt8A0URhrNYmcmzTN/lUYR4BfFvT1e+G+Ox4dT0diKrrJguRhqakAizo4\\nGxpfPWS96yjAhlLjccDVqseefrin7LtRKl3Kf/K7PIplapct8ADoUgimr+KRhU/B\\naqyxlxvXAgMBAAECggEAJuz3kOZvIX2Kw4gGyOtVBWQm+qnnClqtcF8cE16SP7QL\\nDE17gupXAerwrWqu70/diTDe66CiPespsLOC6P7yURN4qkI29+9Ed9OBHOf7gyZo\\nvl9M6pIFCIgzOj+qkIx6AuLe4q9qiLhEzf0npZQW5GCVOtQCAv25WqvZW1R8BcRp\\nOXu/YnydQhtsheB7HgNjdCJepUqlzZR6Iy5zgQvvszPFHCSU9nDLShu8HR25Zssi\\ns70iDdOoxC0br5fYN73yBhEw5TWYHJmLoSQ7NnXE6ZD453wM2syq2pJ3AEnaLXgc\\nWajv0oFMeUzVP3u5llikEPZDcjcS0qL3YJmiS5J6wQKBgQDUcQdYy8lkrDAJ6sEP\\nMpBB+jnzkfe9/K64ofiR8CY1b489cemYrXmMYvkUM3PT3S8m950iA0/tqKPY5Xz+\\nKQhv5rGB6e0aZkc8fF26yLQ6OQ2kivF/aapZtH6FsdCCgPHCY0TwYxSW60HRUNXL\\n1UXKlU40yUn0J7yPrChabdVzNQKBgQDM8T+c3LxWhiWCsFAilW3rXC++x5zDmCwf\\n/lnqTIGM6VsF1TeOklriakF9+lsnLaMtmKF00vHQc7LaO3KUUtVk5Th8Kc1ChB5w\\nyPxgomW/FB/3TJIoa0fIw46I3/flvuck3OA2u15E1JlmRHzh+bx3bF7R8fjBU/oB\\nJgkQgNeIWwKBgBimFKgk3PUlVV2RM11EDKDbG6Y7JXeRveQGRwUHzCcfDouej+/7\\nEMNNKIFDhwjp/PKUgFLV94wnqPsdhWcn86aoKahdL/mELHfEJkvpxZ+Lxx10UZjq\\n9az62ENC4mKB+4sGYZVSqazpFvXmXygLUtGyiSRuxnnhsmspGnWDkOSRAoGBALmj\\nfZ+1QtSNRsUOuEfbW2nqY0VIwvNZj/6bAw98pYzihBTQgjae07xry081zAO9DyZq\\nLzYHLgtIAiYz2yIHtkxiZbvykX9C9d/r7tAJymg+7oWv0mTSaH+uxBmv5nkxZ2a4\\nvFBXgJiQizNbrlNzSAhVHb7GlDFqw/buYR+V1aYpAoGBAJ70rAefLkJyjXreynmX\\nF62/rghChlXTUnUJ3l517fwhFV21qc6MNZNcB9T90OE9TW2+9LH0G9X7NuBVdtHm\\nki/Ab9Q4WpH+3j+4ijLUiIb+dLOzyBKxTaEQYTk5J0qt7y04HDt3Q6IuxbVK4iki\\nqsVGWFDS1HVXb7H9DWNOTMyS\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"llama-index-example@llamaindex-425923.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"115993612305546342970\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/llama-index-example%40llamaindex-425923.iam.gserviceaccount.com\",\n",
    "  \"universe_domain\": \"googleapis.com\"\n",
    "})# loader = GoogleDriveReader(service_account_key=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)\n",
    "# 448896167847-agi7l86q9b5bj4evp7pjg3u8r682f0g8.apps.googleusercontent.com\n",
    "# loader = GoogleDriveReader(448896167847-agi7l86q9b5bj4evp7pjg3u8r682f0g8.apps.googleusercontent.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd896f-111a-4317-895d-8fb6e8142635",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7fb56b73-78f1-41c3-b93e-98d3a701f2c3",
   "metadata": {
    "id": "7fb56b73-78f1-41c3-b93e-98d3a701f2c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 docs\n"
     ]
    }
   ],
   "source": [
    "loader = GoogleDriveReader(service_account_key={\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"llamaindex-425923\",\n",
    "  \"private_key_id\": \"842e330bbcfd7c7525fce7f7d14ab161f056d717\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCqEkUMqdkWMrn6\\nCkePQnTih2EOE/aD66crON+vFLZhC8nwTsbMoHWgu6QegRkn+9mm8/yp1wDuV8jF\\nGztVF4pPA9pHLtoUliAR4qlO71mejElDcr5+9TUEu0BZV5maihQyMOi/ZAgOyx6N\\nwUp1EqUTpt8EY+NyjAVU4EGolPJil0D0ltiu3wUKEYhCRPUifS2aO5iKEk5ipkaq\\nkn87ar3Tt8A0URhrNYmcmzTN/lUYR4BfFvT1e+G+Ox4dT0diKrrJguRhqakAizo4\\nGxpfPWS96yjAhlLjccDVqseefrin7LtRKl3Kf/K7PIplapct8ADoUgimr+KRhU/B\\naqyxlxvXAgMBAAECggEAJuz3kOZvIX2Kw4gGyOtVBWQm+qnnClqtcF8cE16SP7QL\\nDE17gupXAerwrWqu70/diTDe66CiPespsLOC6P7yURN4qkI29+9Ed9OBHOf7gyZo\\nvl9M6pIFCIgzOj+qkIx6AuLe4q9qiLhEzf0npZQW5GCVOtQCAv25WqvZW1R8BcRp\\nOXu/YnydQhtsheB7HgNjdCJepUqlzZR6Iy5zgQvvszPFHCSU9nDLShu8HR25Zssi\\ns70iDdOoxC0br5fYN73yBhEw5TWYHJmLoSQ7NnXE6ZD453wM2syq2pJ3AEnaLXgc\\nWajv0oFMeUzVP3u5llikEPZDcjcS0qL3YJmiS5J6wQKBgQDUcQdYy8lkrDAJ6sEP\\nMpBB+jnzkfe9/K64ofiR8CY1b489cemYrXmMYvkUM3PT3S8m950iA0/tqKPY5Xz+\\nKQhv5rGB6e0aZkc8fF26yLQ6OQ2kivF/aapZtH6FsdCCgPHCY0TwYxSW60HRUNXL\\n1UXKlU40yUn0J7yPrChabdVzNQKBgQDM8T+c3LxWhiWCsFAilW3rXC++x5zDmCwf\\n/lnqTIGM6VsF1TeOklriakF9+lsnLaMtmKF00vHQc7LaO3KUUtVk5Th8Kc1ChB5w\\nyPxgomW/FB/3TJIoa0fIw46I3/flvuck3OA2u15E1JlmRHzh+bx3bF7R8fjBU/oB\\nJgkQgNeIWwKBgBimFKgk3PUlVV2RM11EDKDbG6Y7JXeRveQGRwUHzCcfDouej+/7\\nEMNNKIFDhwjp/PKUgFLV94wnqPsdhWcn86aoKahdL/mELHfEJkvpxZ+Lxx10UZjq\\n9az62ENC4mKB+4sGYZVSqazpFvXmXygLUtGyiSRuxnnhsmspGnWDkOSRAoGBALmj\\nfZ+1QtSNRsUOuEfbW2nqY0VIwvNZj/6bAw98pYzihBTQgjae07xry081zAO9DyZq\\nLzYHLgtIAiYz2yIHtkxiZbvykX9C9d/r7tAJymg+7oWv0mTSaH+uxBmv5nkxZ2a4\\nvFBXgJiQizNbrlNzSAhVHb7GlDFqw/buYR+V1aYpAoGBAJ70rAefLkJyjXreynmX\\nF62/rghChlXTUnUJ3l517fwhFV21qc6MNZNcB9T90OE9TW2+9LH0G9X7NuBVdtHm\\nki/Ab9Q4WpH+3j+4ijLUiIb+dLOzyBKxTaEQYTk5J0qt7y04HDt3Q6IuxbVK4iki\\nqsVGWFDS1HVXb7H9DWNOTMyS\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"llama-index-example@llamaindex-425923.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"115993612305546342970\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/llama-index-example%40llamaindex-425923.iam.gserviceaccount.com\",\n",
    "  \"universe_domain\": \"googleapis.com\"\n",
    "})# loader = GoogleDriveReader(service_account_key=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)\n",
    "# 448896167847-agi7l86q9b5bj4evp7pjg3u8r682f0g8.apps.googleusercontent.com\n",
    "# loader = GoogleDriveReader(448896167847-agi7l86q9b5bj4evp7pjg3u8r682f0g8.apps.googleusercontent.com)\n",
    "\n",
    "def load_data(folder_id: str):\n",
    "    docs = loader.load_data(folder_id=folder_id)\n",
    "    print(len(docs), \"docs\")\n",
    "    # for doc in docs:\n",
    "    #     doc.id_ = doc.metadata[\"file_name\"]\n",
    "    return docs\n",
    "\n",
    "docs = load_data(folder_id=\"1UBvqhlESL6r8fLzjcAHuAxgH4vbPvT7K\") # personal\n",
    "# docs = load_data(folder_id=\"1RFhr3-KmOZCR5rtp4dlOMNl3LKe1kOA5\") # orig\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "21a8bd50-c2a5-496e-a3d1-933483efd61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 docs\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "loader = SimpleDirectoryReader(\"data\")\n",
    "\n",
    "def load_data():\n",
    "    docs = loader.load_data()\n",
    "    print(len(docs), \"docs\")\n",
    "    # for doc in docs:\n",
    "    #     doc.id_ = doc.metadata[\"file_name\"]\n",
    "    return docs\n",
    "\n",
    "# docs = load_data(folder_id=\"1UBvqhlESL6r8fLzjcAHuAxgH4vbPvT7K\") # personal\n",
    "docs = load_data()\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7e678f44-6372-4234-8abb-7b1c92ce85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    # print(doc.metadata)\n",
    "    # print(doc.id_)\n",
    "    # break\n",
    "    doc.id_ = doc.metadata[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c77f74b2-9bbe-46d6-b35f-23ea757b315b",
   "metadata": {
    "id": "c77f74b2-9bbe-46d6-b35f-23ea757b315b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested 1 Nodes\n"
     ]
    }
   ],
   "source": [
    "nodes = pipeline.run(documents=docs)\n",
    "print(f\"Ingested {len(nodes)} Nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae510add-f8d3-4fb3-a351-1cc7a5fe9e6b",
   "metadata": {
    "id": "ae510add-f8d3-4fb3-a351-1cc7a5fe9e6b"
   },
   "source": [
    "Since this is our first time starting up the vector store, we see that we've transformed/ingested all the documents into it (by chunking, and then by embedding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687636-45e3-4038-b72e-b8c2d86baf56",
   "metadata": {
    "id": "f9687636-45e3-4038-b72e-b8c2d86baf56"
   },
   "source": [
    "### Ask Questions over Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0c54d927-3b56-4844-89c5-61a5aac1df6c",
   "metadata": {
    "id": "0c54d927-3b56-4844-89c5-61a5aac1df6c"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4o\", )\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "65ddcc68-c426-40f4-ac3b-16495855e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This documentation appears to be about the Ursina game engine. It includes an HTML template for generating an API reference page, which lists various components and modules of the engine. These components are categorized into groups such as Basics, Core Modules, Graphics, Procedural Models, Animation, Math, Gameplay, Collision, Prefabs, UI, Editor, Scripts, Assets, and Shaders. Additionally, there are references to tutorials like an introduction and a platformer tutorial, which are likely aimed at helping users learn how to use the Ursina engine effectively.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is this documentation about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "49133858-de8f-4cbe-bc83-c951c5bbe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempt to use Pydantic Output response formats\n",
    "# from typing import List\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# class Program(BaseModel):\n",
    "#     \"\"\"Data model for python program.\"\"\"\n",
    "\n",
    "#     name: str\n",
    "#     python_code : str\n",
    "#     explanation : str\n",
    "\n",
    "# query_engine = index.as_query_engine(llm=llm, response_model=\"refine\", output_cls=Program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1c3aec73-a946-44fc-8a0c-c12081bf6028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "77047.78s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/cb/e7/2556005908c42be3ab384e289729a21766c761a21186f2f433aa475e859f/langchain-0.2.3-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/18/d6/6eb8bf9b340b8827874a9c065d195af66e3287be0832a7c7143f30747c6e/langchain_core-0.2.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.2.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/a9/d9/31b1b5415be5201ec1ba34ab04f47a92c69174d7817d70b51693fb60e780/langchain_text_splitters-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.17 from https://files.pythonhosted.org/packages/78/cb/2dc0126dfa6be3471c397c7e1a3773fea25e4c911f99b1bbb7da7a77d273/langsmith-0.1.75-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.75-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (2.7.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/27/e1/8ab6b5491a79a481bfb2e21ff6a75c10d5c73b50192634b41210ee75a2ca/orjson-3.10.4-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
      "  Downloading orjson-3.10.4-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/emily/Desktop/code repos/log-analysis/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.4-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (254 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging, orjson, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed jsonpatch-1.33 langchain-0.2.3 langchain-core-0.2.5 langchain-text-splitters-0.2.1 langsmith-0.1.75 orjson-3.10.4 packaging-23.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2cdb1fdc-af39-4afd-9629-78b54dc5fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.output_parsers import LangchainOutputParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# define output schema\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"Python code\",\n",
    "        description=\"Write python code that correspond to the query\",\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"Explanation\",\n",
    "        description=\"Describe what you've done\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# define output parser\n",
    "lc_output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    response_schemas\n",
    ")\n",
    "output_parser = LangchainOutputParser(lc_output_parser)\n",
    "print(\"Output parseroutput_parser)\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4o\", output_parser=output_parser)\n",
    "# obtain a structured response\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "# response = query_engine.query(\n",
    "#     \"What are a few things the author did growing up?\",\n",
    "# )\n",
    "# print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1ad8e178-60fd-4405-b74f-0fdbd7b0ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Python code': \"from ursina import *\\n\\nif __name__ == '__main__':\\n    app = Ursina()\\n\\ncamera.orthographic = True\\ncamera.fov = 4\\ncamera.position = (1, 1)\\nText.default_resolution *= 2\\n\\nplayer = Entity(name='o', color=color.azure)\\ncursor = Tooltip(player.name, color=player.color, origin=(0,0), scale=4, enabled=True)\\ncursor.background.color = color.clear\\nbg = Entity(parent=scene, model='quad', texture='shore', scale=(16,8), z=10, color=color.light_gray)\\nmouse.visible = False\\n\\n# create a matrix to store the buttons in. makes it easier to check for victory\\nboard = [[None for x in range(3)] for y in range(3)]\\n\\nfor y in range(3):\\n    for x in range(3):\\n        b = Button(parent=scene, position=(x,y))\\n        board[x][y] = b\\n\\n        def on_click(b=b):\\n            b.text = player.name\\n            b.color = player.color\\n            b.collision = False\\n            check_for_victory()\\n\\n            if player.name == 'o':\\n                player.name = 'x'\\n                player.color = color.orange\\n            else:\\n                player.name = 'o'\\n                player.color = color.azure\\n\\n            cursor.text = player.name\\n            cursor.color = player.color\\n\\n        b.on_click = on_click\\n\\n\\ndef check_for_victory():\\n    name = player.name\\n\\n    won = (\\n    (board[0][0].text == name and board[1][0].text == name and board[2][0].text == name) or # across the bottom\\n    (board[0][1].text == name and board[1][1].text == name and board[2][1].text == name) or # across the middle\\n    (board[0][2].text == name and board[1][2].text == name and board[2][2].text == name) or # across the top\\n    (board[0][0].text == name and board[0][1].text == name and board[0][2].text == name) or # down the left side\\n    (board[1][0].text == name and board[1][1].text == name and board[1][2].text == name) or # down the middle\\n    (board[2][0].text == name and board[2][1].text == name and board[2][2].text == name) or # down the right side\\n    (board[0][0].text == name and board[1][1].text == name and board[2][2].text == name) or # diagonal /\\n    (board[0][2].text == name and board[1][1].text == name and board[2][0].text == name))   # diagonal \\\\\\n\\n    if won:\\n        print('winner is:', name)\\n        cursor.text = ''\\n        mouse.visible = True\\n        Panel(z=1, scale=10, model='quad')\\n        t = Text(f'player\\\\n{name}\\\\nwon!', scale=3, origin=(0,0), background=True)\\n        t.create_background(padding=(.5,.25), radius=Text.size/2)\\n        t.background.color = player.color.tint(-.2)\\n\\nif __name__ == '__main__':\\n    app.run()\", 'Explanation': \"The provided Python code creates a Tic Tac Toe game using the Ursina game engine. The game initializes a 3x3 grid of buttons representing the board. Players take turns clicking the buttons to place their marks ('o' or 'x'). The game checks for a victory condition after each move and announces the winner if a player wins.\"}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Write a tic tac toe game\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b8e2c755-5ed9-4409-accb-e9b6d0785041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.base.response.schema.Response'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='{\\'Python code\\': \"from ursina import *\\\\n\\\\nif __name__ == \\'__main__\\':\\\\n    app = Ursina()\\\\n\\\\ncamera.orthographic = True\\\\ncamera.fov = 4\\\\ncamera.position = (1, 1)\\\\nText.default_resolution *= 2\\\\n\\\\nplayer = Entity(name=\\'o\\', color=color.azure)\\\\ncursor = Tooltip(player.name, color=player.color, origin=(0,0), scale=4, enabled=True)\\\\ncursor.background.color = color.clear\\\\nbg = Entity(parent=scene, model=\\'quad\\', texture=\\'shore\\', scale=(16,8), z=10, color=color.light_gray)\\\\nmouse.visible = False\\\\n\\\\n# create a matrix to store the buttons in. makes it easier to check for victory\\\\nboard = [[None for x in range(3)] for y in range(3)]\\\\n\\\\nfor y in range(3):\\\\n    for x in range(3):\\\\n        b = Button(parent=scene, position=(x,y))\\\\n        board[x][y] = b\\\\n\\\\n        def on_click(b=b):\\\\n            b.text = player.name\\\\n            b.color = player.color\\\\n            b.collision = False\\\\n            check_for_victory()\\\\n\\\\n            if player.name == \\'o\\':\\\\n                player.name = \\'x\\'\\\\n                player.color = color.orange\\\\n            else:\\\\n                player.name = \\'o\\'\\\\n                player.color = color.azure\\\\n\\\\n            cursor.text = player.name\\\\n            cursor.color = player.color\\\\n\\\\n        b.on_click = on_click\\\\n\\\\n\\\\ndef check_for_victory():\\\\n    name = player.name\\\\n\\\\n    won = (\\\\n    (board[0][0].text == name and board[1][0].text == name and board[2][0].text == name) or # across the bottom\\\\n    (board[0][1].text == name and board[1][1].text == name and board[2][1].text == name) or # across the middle\\\\n    (board[0][2].text == name and board[1][2].text == name and board[2][2].text == name) or # across the top\\\\n    (board[0][0].text == name and board[0][1].text == name and board[0][2].text == name) or # down the left side\\\\n    (board[1][0].text == name and board[1][1].text == name and board[1][2].text == name) or # down the middle\\\\n    (board[2][0].text == name and board[2][1].text == name and board[2][2].text == name) or # down the right side\\\\n    (board[0][0].text == name and board[1][1].text == name and board[2][2].text == name) or # diagonal /\\\\n    (board[0][2].text == name and board[1][1].text == name and board[2][0].text == name))   # diagonal \\\\\\\\\\\\n\\\\n    if won:\\\\n        print(\\'winner is:\\', name)\\\\n        cursor.text = \\'\\'\\\\n        mouse.visible = True\\\\n        Panel(z=1, scale=10, model=\\'quad\\')\\\\n        t = Text(f\\'player\\\\\\\\n{name}\\\\\\\\nwon!\\', scale=3, origin=(0,0), background=True)\\\\n        t.create_background(padding=(.5,.25), radius=Text.size/2)\\\\n        t.background.color = player.color.tint(-.2)\\\\n\\\\nif __name__ == \\'__main__\\':\\\\n    app.run()\", \\'Explanation\\': \"The provided Python code creates a Tic Tac Toe game using the Ursina game engine. The game initializes a 3x3 grid of buttons representing the board. Players take turns clicking the buttons to place their marks (\\'o\\' or \\'x\\'). The game checks for a victory condition after each move and announces the winner if a player wins.\"}', source_nodes=[NodeWithScore(node=TextNode(id_='678815a1-3564-4a6e-b0fb-cadfa13ed155', embedding=None, metadata={'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/tic_tac_toe.txt', 'file_name': 'tic_tac_toe.txt', 'file_type': 'text/plain', 'file_size': 2783, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='tic_tac_toe.txt', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/tic_tac_toe.txt', 'file_name': 'tic_tac_toe.txt', 'file_type': 'text/plain', 'file_size': 2783, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}, hash='5c57aa798e8491be3a0aaab37169460c8ac38eee8bee84e7ff60563eb35d40f8')}, text='# title ursina engine documentation\\n# insert menu.txt\\n\\n### Tic Tac Toe\\n<a href=\"https://github.com/pokepetter/ursina/blob/master/samples/tic_tac_toe.py\">https://github.com/pokepetter/ursina/blob/master/samples/tic_tac_toe.py</a>\\n\\n# image icons/tic_tac_toe.jpg\\n```from ursina import *\\n\\nif __name__ == \\'__main__\\':\\n    app = Ursina()\\n\\ncamera.orthographic = True\\ncamera.fov = 4\\ncamera.position = (1, 1)\\nText.default_resolution *= 2\\n\\nplayer = Entity(name=\\'o\\', color=color.azure)\\ncursor = Tooltip(player.name, color=player.color, origin=(0,0), scale=4, enabled=True)\\ncursor.background.color = color.clear\\nbg = Entity(parent=scene, model=\\'quad\\', texture=\\'shore\\', scale=(16,8), z=10, color=color.light_gray)\\nmouse.visible = False\\n\\n# create a matrix to store the buttons in. makes it easier to check for victory\\nboard = [[None for x in range(3)] for y in range(3)]\\n\\nfor y in range(3):\\n    for x in range(3):\\n        b = Button(parent=scene, position=(x,y))\\n        board[x][y] = b\\n\\n        def on_click(b=b):\\n            b.text = player.name\\n            b.color = player.color\\n            b.collision = False\\n            check_for_victory()\\n\\n            if player.name == \\'o\\':\\n                player.name = \\'x\\'\\n                player.color = color.orange\\n            else:\\n                player.name = \\'o\\'\\n                player.color = color.azure\\n\\n            cursor.text = player.name\\n            cursor.color = player.color\\n\\n        b.on_click = on_click\\n\\n\\ndef check_for_victory():\\n    name = player.name\\n\\n    won = (\\n    (board[0][0].text == name and board[1][0].text == name and board[2][0].text == name) or # across the bottom\\n    (board[0][1].text == name and board[1][1].text == name and board[2][1].text == name) or # across the middle\\n    (board[0][2].text == name and board[1][2].text == name and board[2][2].text == name) or # across the top\\n    (board[0][0].text == name and board[0][1].text == name and board[0][2].text == name) or # down the left side\\n    (board[1][0].text == name and board[1][1].text == name and board[1][2].text == name) or # down the middle\\n    (board[2][0].text == name and board[2][1].text == name and board[2][2].text == name) or # down the right side\\n    (board[0][0].text == name and board[1][1].text == name and board[2][2].text == name) or # diagonal /\\n    (board[0][2].text == name and board[1][1].text == name and board[2][0].text == name))   # diagonal \\\\\\n\\n    if won:\\n        print(\\'winner is:\\', name)\\n        cursor.text = \\'\\'\\n        mouse.visible = True\\n        Panel(z=1, scale=10, model=\\'quad\\')\\n        t = Text(f\\'player\\\\n{name}\\\\nwon!\\', scale=3, origin=(0,0), background=True)\\n        t.create_background(padding=(.5,.25), radius=Text.size/2)\\n        t.background.color = player.color.tint(-.2)\\n\\nif __name__ == \\'__main__\\':\\n    app.run()\\n```', start_char_idx=0, end_char_idx=2783, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7232056856160001), NodeWithScore(node=TextNode(id_='bc313789-62b1-46c6-8874-7e7fcc389863', embedding=None, metadata={'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/samples.txt', 'file_name': 'samples.txt', 'file_type': 'text/plain', 'file_size': 773, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='samples.txt', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/samples.txt', 'file_name': 'samples.txt', 'file_type': 'text/plain', 'file_size': 773, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}, hash='5442d946f9292e990ccb7515060d79fec91c93a53d2b430e049be558f1dae3b3')}, text=\"# title ursina engine samples\\n# insert menu.txt\\n\\n### Samples\\n[Tic Tac Toe, tic_tac_toe.html, icons/tic_tac_toe.jpg]\\n[Inventory, inventory.html, icons/inventory.jpg]\\n[Pong, pong.html, icons/pong.jpg]\\n[Minecraft Clone, minecraft_clone.html, icons/minecraft_clone.jpg]\\n[Rubik's Cube, rubiks_cube.html, icons/rubiks_cube.jpg]\\n[Clicker Game, clicker_game.html, icons/clicker_game.jpg]\\n[Platformer, platformer.html, icons/platformer.jpg]\\n[FPS, fps.html, icons/fps.jpg]\\n[Particle System, particle_system.html, icons/particle_system.jpg]\\n[Column Graph, column_graph.html, icons/column_graph.jpg]\\n[Value of Life, https://github.com/pokepetter/ld44_life_is_currency, icons/value_of_life_icon.jpg]\\n[Castaway, https://github.com/pokepetter/pyweek_30_castaway, icons/castaway_icon.jpg]\", start_char_idx=0, end_char_idx=772, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.688014268875)], metadata={'678815a1-3564-4a6e-b0fb-cadfa13ed155': {'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/tic_tac_toe.txt', 'file_name': 'tic_tac_toe.txt', 'file_type': 'text/plain', 'file_size': 2783, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}, 'bc313789-62b1-46c6-8874-7e7fcc389863': {'file_path': '/Users/emily/Desktop/code repos/log-analysis/llamaindex-learn/data/samples.txt', 'file_name': 'samples.txt', 'file_type': 'text/plain', 'file_size': 773, 'creation_date': '2024-06-09', 'last_modified_date': '2024-06-08'}})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ab7834cf-890c-49a6-b41b-c27698ceabe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Code:\n",
      " from ursina import *\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app = Ursina()\n",
      "\n",
      "camera.orthographic = True\n",
      "camera.fov = 4\n",
      "camera.position = (1, 1)\n",
      "Text.default_resolution *= 2\n",
      "\n",
      "player = Entity(name='o', color=color.azure)\n",
      "cursor = Tooltip(player.name, color=player.color, origin=(0,0), scale=4, enabled=True)\n",
      "cursor.background.color = color.clear\n",
      "bg = Entity(parent=scene, model='quad', texture='shore', scale=(16,8), z=10, color=color.light_gray)\n",
      "mouse.visible = False\n",
      "\n",
      "# create a matrix to store the buttons in. makes it easier to check for victory\n",
      "board = [[None for x in range(3)] for y in range(3)]\n",
      "\n",
      "for y in range(3):\n",
      "    for x in range(3):\n",
      "        b = Button(parent=scene, position=(x,y))\n",
      "        board[x][y] = b\n",
      "\n",
      "        def on_click(b=b):\n",
      "            b.text = player.name\n",
      "            b.color = player.color\n",
      "            b.collision = False\n",
      "            check_for_victory()\n",
      "\n",
      "            if player.name == 'o':\n",
      "                player.name = 'x'\n",
      "                player.color = color.orange\n",
      "            else:\n",
      "                player.name = 'o'\n",
      "                player.color = color.azure\n",
      "\n",
      "            cursor.text = player.name\n",
      "            cursor.color = player.color\n",
      "\n",
      "        b.on_click = on_click\n",
      "\n",
      "\n",
      "def check_for_victory():\n",
      "    name = player.name\n",
      "\n",
      "    won = (\n",
      "    (board[0][0].text == name and board[1][0].text == name and board[2][0].text == name) or # across the bottom\n",
      "    (board[0][1].text == name and board[1][1].text == name and board[2][1].text == name) or # across the middle\n",
      "    (board[0][2].text == name and board[1][2].text == name and board[2][2].text == name) or # across the top\n",
      "    (board[0][0].text == name and board[0][1].text == name and board[0][2].text == name) or # down the left side\n",
      "    (board[1][0].text == name and board[1][1].text == name and board[1][2].text == name) or # down the middle\n",
      "    (board[2][0].text == name and board[2][1].text == name and board[2][2].text == name) or # down the right side\n",
      "    (board[0][0].text == name and board[1][1].text == name and board[2][2].text == name) or # diagonal /\n",
      "    (board[0][2].text == name and board[1][1].text == name and board[2][0].text == name))   # diagonal \\\n",
      "\n",
      "    if won:\n",
      "        print('winner is:', name)\n",
      "        cursor.text = ''\n",
      "        mouse.visible = True\n",
      "        Panel(z=1, scale=10, model='quad')\n",
      "        t = Text(f'player\\n{name}\\nwon!', scale=3, origin=(0,0), background=True)\n",
      "        t.create_background(padding=(.5,.25), radius=Text.size/2)\n",
      "        t.background.color = player.color.tint(-.2)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run()\n",
      "\n",
      "Explanation:\n",
      " The provided Python code creates a Tic Tac Toe game using the Ursina game engine. The game initializes a 3x3 grid of buttons representing the board. Players take turns clicking the buttons to place their marks ('o' or 'x'). The game checks for a victory condition after each move and announces the winner if a player wins.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Assuming response_obj is your Response object\n",
    "response_str = response.response\n",
    "\n",
    "# Parse the string representation of the dictionary\n",
    "response_dict = ast.literal_eval(response_str)\n",
    "\n",
    "# Extract 'Python code' and 'Explanation'\n",
    "python_code = response_dict.get('Python code')\n",
    "explanation = response_dict.get('Explanation')\n",
    "\n",
    "print(\"Python Code:\\n\", python_code)\n",
    "print(\"\\nExplanation:\\n\", explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3881daf7-67ef-4b3a-87d7-a227a4307126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['response_synthesizer:text_qa_template', 'response_synthesizer:refine_template'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.get_prompts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69e2c4-3ff1-40dc-b07b-17307d53ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## product\n",
    "# chat with your documentation\n",
    "# iteratively edit code?\n",
    "\n",
    "\n",
    "## todos\n",
    "# turn the above local file upload / enter path into chatbot & pipe it into UI to show dad\n",
    "# execute the output code\n",
    "# documentation parsing into structured pydantic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8e03495a-7c01-4530-a12d-feb03f26abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The examples provided are:\n",
      "1. Tic Tac Toe\n",
      "2. Inventory\n",
      "3. Pong\n",
      "4. Minecraft Clone\n",
      "5. Rubik's Cube\n",
      "6. Clicker Game\n",
      "7. Platformer\n",
      "8. FPS\n",
      "9. Particle System\n",
      "10. Column Graph\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the examples provided here?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "442142e7-be32-4b47-9b17-daf34dbd9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this engine, you can build various types of games and interactive applications. You can start with simple projects like creating a window and rendering a colored cube with basic controls. As you progress, you can create more complex scenes such as a solar system using spheres, or a landscape with moving planes and textured cubes. The engine also supports advanced features like texturing, texture animations, alpha blending, and mouse collisions, allowing you to develop more sophisticated and interactive environments.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What can I build with this engine?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "14315dca-ba7b-495b-a848-d5ffd64a39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a Tic Tac Toe game using the Ursina engine, you can use the following code:\n",
      "\n",
      "```python\n",
      "from ursina import *\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app = Ursina()\n",
      "\n",
      "camera.orthographic = True\n",
      "camera.fov = 4\n",
      "camera.position = (1, 1)\n",
      "Text.default_resolution *= 2\n",
      "\n",
      "player = Entity(name='o', color=color.azure)\n",
      "cursor = Tooltip(player.name, color=player.color, origin=(0,0), scale=4, enabled=True)\n",
      "cursor.background.color = color.clear\n",
      "bg = Entity(parent=scene, model='quad', texture='shore', scale=(16,8), z=10, color=color.light_gray)\n",
      "mouse.visible = False\n",
      "\n",
      "# create a matrix to store the buttons in. makes it easier to check for victory\n",
      "board = [[None for x in range(3)] for y in range(3)]\n",
      "\n",
      "for y in range(3):\n",
      "    for x in range(3):\n",
      "        b = Button(parent=scene, position=(x,y))\n",
      "        board[x][y] = b\n",
      "\n",
      "        def on_click(b=b):\n",
      "            b.text = player.name\n",
      "            b.color = player.color\n",
      "            b.collision = False\n",
      "            check_for_victory()\n",
      "\n",
      "            if player.name == 'o':\n",
      "                player.name = 'x'\n",
      "                player.color = color.orange\n",
      "            else:\n",
      "                player.name = 'o'\n",
      "                player.color = color.azure\n",
      "\n",
      "            cursor.text = player.name\n",
      "            cursor.color = player.color\n",
      "\n",
      "        b.on_click = on_click\n",
      "\n",
      "\n",
      "def check_for_victory():\n",
      "    name = player.name\n",
      "\n",
      "    won = (\n",
      "    (board[0][0].text == name and board[1][0].text == name and board[2][0].text == name) or # across the bottom\n",
      "    (board[0][1].text == name and board[1][1].text == name and board[2][1].text == name) or # across the middle\n",
      "    (board[0][2].text == name and board[1][2].text == name and board[2][2].text == name) or # across the top\n",
      "    (board[0][0].text == name and board[0][1].text == name and board[0][2].text == name) or # down the left side\n",
      "    (board[1][0].text == name and board[1][1].text == name and board[1][2].text == name) or # down the middle\n",
      "    (board[2][0].text == name and board[2][1].text == name and board[2][2].text == name) or # down the right side\n",
      "    (board[0][0].text == name and board[1][1].text == name and board[2][2].text == name) or # diagonal /\n",
      "    (board[0][2].text == name and board[1][1].text == name and board[2][0].text == name))   # diagonal \\\n",
      "\n",
      "    if won:\n",
      "        print('winner is:', name)\n",
      "        cursor.text = ''\n",
      "        mouse.visible = True\n",
      "        Panel(z=1, scale=10, model='quad')\n",
      "        t = Text(f'player\\n{name}\\nwon!', scale=3, origin=(0,0), background=True)\n",
      "        t.create_background(padding=(.5,.25), radius=Text.size/2)\n",
      "        t.background.color = player.color.tint(-.2)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run()\n",
      "```\n",
      "\n",
      "This code sets up a basic Tic Tac Toe game using the Ursina engine. It initializes the game window, sets up the camera, and creates a 3x3 grid of buttons. Players take turns clicking on the buttons to place their marks ('o' or 'x'). The game checks for a victory condition after each move and announces the winner.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Write a tic tac toe game\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b5201-0b69-4419-9294-c03ee85b0755",
   "metadata": {
    "id": "800b5201-0b69-4419-9294-c03ee85b0755",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Modify and Reload the Data\n",
    "\n",
    "Let's try modifying our ingested data!\n",
    "\n",
    "We modify the \"Q&A\" doc to include an extra \"structured analytics\" block of text. See our [updated document](https://docs.google.com/document/d/1QQMKNAgyplv2IUOKNClEBymOFaASwmsZFoLmO_IeSTw/edit?usp=sharing) as a reference.\n",
    "\n",
    "Now let's rerun the ingestion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490fbb8-82ec-4284-a19d-1a8ca69da2a4",
   "metadata": {
    "id": "d490fbb8-82ec-4284-a19d-1a8ca69da2a4"
   },
   "outputs": [],
   "source": [
    "docs = load_data(folder_id=\"1RFhr3-KmOZCR5rtp4dlOMNl3LKe1kOA5\")\n",
    "nodes = pipeline.run(documents=docs)\n",
    "print(f\"Ingested {len(nodes)} Nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768505db-02ee-4929-a8e7-1ee127356c98",
   "metadata": {
    "id": "768505db-02ee-4929-a8e7-1ee127356c98"
   },
   "source": [
    "Notice how only one node is ingested. This is beacuse only one document changed, while the other documents stayed the same. This means that we only need to re-transform and re-embed one document!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba5205-09d7-46f0-8a97-ac58c3f9b649",
   "metadata": {
    "id": "56ba5205-09d7-46f0-8a97-ac58c3f9b649"
   },
   "source": [
    "### Ask Questions over New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d5f4b-7818-437b-ac33-ce8257e00048",
   "metadata": {
    "id": "b52d5f4b-7818-437b-ac33-ce8257e00048"
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf1b0b-f6f1-45eb-ac61-a154a66c57d7",
   "metadata": {
    "id": "b5cf1b0b-f6f1-45eb-ac61-a154a66c57d7"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What are the sub-types of question answering?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cce9e-567a-4ef4-8793-875880e09756",
   "metadata": {
    "id": "486cce9e-567a-4ef4-8793-875880e09756",
    "outputId": "a4aba8c9-9a29-4ef8-8c4e-78778b3be90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sub-types of question answering mentioned in the context are semantic search, summarization, and structured analytics.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
